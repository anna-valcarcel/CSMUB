{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497f36ae-4f29-4ab9-b711-c40c6bec0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pysheds netCDF4 fiona geopandas xarray pyshp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d192431-8393-4d98-8561-cb00c9154283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapefile\n",
    "import os\n",
    "\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "from shapely.geometry import Point, shape, box, mapping\n",
    "from shapely.vectorized import contains\n",
    "from shapely.strtree import STRtree\n",
    "\n",
    "from rasterio.coords import BoundingBox\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddbe9ba-e621-4d96-b8c7-ed3e42b6722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import shapely\n",
    "\n",
    "def contains(geom, lon, lat):\n",
    "    \"\"\"Check if lon/lat points are within the geometry.\"\"\"\n",
    "    points = gpd.GeoSeries([Point(xy) for xy in zip(lon, lat)], crs=\"EPSG:4326\")\n",
    "    return points.within(geom)\n",
    "\n",
    "def average_precip_single(shp_input, nc_dir, date_str, plot=True):\n",
    "    filename = f\"IMERG-Final.CLIM.2001-2022.{date_str}.V07B.nc4\"\n",
    "    filepath = os.path.join(nc_dir, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"File not found:\", filepath)\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        # Load shapefile and reproject\n",
    "        shp = gpd.read_file(shp_input).to_crs('EPSG:4326')\n",
    "        geom = shp.geometry.union_all()  # Updated per deprecation warning\n",
    "\n",
    "        # Open NetCDF\n",
    "        with nc.Dataset(filepath) as dataset:\n",
    "            precip = dataset.variables['precipitation'][:]\n",
    "            lat = dataset.variables['lat'][:]\n",
    "            lon = dataset.variables['lon'][:]\n",
    "\n",
    "        # Handle time dimension\n",
    "        if precip.ndim == 3:\n",
    "            precip = precip.mean(axis=0)\n",
    "\n",
    "        # Get bounding box of shape\n",
    "        minlon, minlat, maxlon, maxlat = geom.bounds\n",
    "\n",
    "        # Create lat/lon masks\n",
    "        lat_mask = (lat >= minlat) & (lat <= maxlat)\n",
    "        lon_mask = (lon >= minlon) & (lon <= maxlon)\n",
    "\n",
    "        # Safe mask check\n",
    "        if not lat_mask.any() or not lon_mask.any():\n",
    "            print(\"No lat/lon points within shapefile bounds.\")\n",
    "            return np.nan\n",
    "\n",
    "        # Slice arrays safely\n",
    "        lat_filtered = lat[lat_mask]\n",
    "        lon_filtered = lon[lon_mask]\n",
    "\n",
    "        if precip.shape[0] < lat_mask.sum() or precip.shape[1] < lon_mask.sum():\n",
    "            print(\"Filtered indices exceed precip array dimensions.\")\n",
    "            return np.nan\n",
    "\n",
    "        precip_filtered = precip[np.ix_(lat_mask, lon_mask)]\n",
    "\n",
    "        # Create grids\n",
    "        lon_grid, lat_grid = np.meshgrid(lon_filtered, lat_filtered)\n",
    "\n",
    "        # Optional: visualize the contour plot\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ctf = ax.contourf(lon_grid, lat_grid, precip_filtered, cmap='viridis', levels=15)\n",
    "            shp.boundary.plot(ax=ax, color='red', linewidth=1)\n",
    "            plt.colorbar(ctf, ax=ax, label='Precipitation (mm)')\n",
    "            ax.set_title(f'Precipitation - {date_str}')\n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Flatten and apply geometry mask\n",
    "        lon_flat = lon_grid.ravel()\n",
    "        lat_flat = lat_grid.ravel()\n",
    "        precip_flat = precip_filtered.ravel()\n",
    "\n",
    "        mask = contains(geom, lon_flat, lat_flat)\n",
    "\n",
    "        if not np.any(mask):\n",
    "            print(\"No points inside the geometry.\")\n",
    "            return np.nan\n",
    "\n",
    "        avg_precip = np.nanmean(precip_flat[mask])\n",
    "        return avg_precip\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {date_str}, {shp_input}: {e}\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74fdc5b8-6f9a-4d8d-b8b7-f740e06ea4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "opened = []\n",
    "\n",
    "file_path = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/ALL_STATIONS_ALL_MONTHS.csv'\n",
    "\n",
    "# Export to a CSV file\n",
    "stations_df = pd.read_csv(file_path)\n",
    "# print(stations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4ccd61-75a0-493d-817f-35a41ec91879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat/lon indices exceed precipitation array shape.\n",
      "Lat index max: 682 Lat shape: 3599\n",
      "Lon index max: 2102 Lon shape: 1799\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1965 is out of bounds for axis 1 with size 1799",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m lat_filtered \u001b[38;5;241m=\u001b[39m lat[lat_idx]\n\u001b[1;32m     74\u001b[0m lon_filtered \u001b[38;5;241m=\u001b[39m lon[lon_idx]\n\u001b[0;32m---> 75\u001b[0m precip_filtered \u001b[38;5;241m=\u001b[39m precip[np\u001b[38;5;241m.\u001b[39mix_(lat_idx, lon_idx)]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# ==== CREATE MESHGRID ====\u001b[39;00m\n\u001b[1;32m     80\u001b[0m lon_grid, lat_grid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(lon_filtered, lat_filtered)\n",
      "File \u001b[0;32m/global/software/rocky-8.x86_64/manual/modules/langs/anaconda3/2024.02-1/lib/python3.11/site-packages/numpy/ma/core.py:3228\u001b[0m, in \u001b[0;36mMaskedArray.__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;124;03mx.__getitem__(y) <==> x[y]\u001b[39;00m\n\u001b[1;32m   3220\u001b[0m \n\u001b[1;32m   3221\u001b[0m \u001b[38;5;124;03mReturn the item described by i, as a masked array.\u001b[39;00m\n\u001b[1;32m   3222\u001b[0m \n\u001b[1;32m   3223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;66;03m# We could directly use ndarray.__getitem__ on self.\u001b[39;00m\n\u001b[1;32m   3225\u001b[0m \u001b[38;5;66;03m# But then we would have to modify __array_finalize__ to prevent the\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;66;03m# mask of being reshaped if it hasn't been set up properly yet\u001b[39;00m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;66;03m# So it's easier to stick to the current version\u001b[39;00m\n\u001b[0;32m-> 3228\u001b[0m dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[indx]\n\u001b[1;32m   3229\u001b[0m _mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask\n\u001b[1;32m   3231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_scalar\u001b[39m(m):\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1965 is out of bounds for axis 1 with size 1799"
     ]
    }
   ],
   "source": [
    "precip = np.zeros(len(stations_df))\n",
    "    \n",
    "for i in range(0,1):\n",
    "# i = 0\n",
    "    \n",
    "    date = stations_df['Date']\n",
    "    number = stations_df['GRDC_No'][i]\n",
    "    shp_log = stations_df['SHP']\n",
    "    \n",
    "    # Read the shapefiles\n",
    "    shapefile1 = f'/global/home/users/arvalcarcel/ondemand/data/dem/{number}/{number}.shp' # delineated shapefile # delineated shapefile\n",
    "    shapefile2 = f'/global/scratch/users/arvalcarcel/CSMUB/DATA/SHAPEFILES/{number}/{number}.shp' # GRDC shapefile\n",
    "    \n",
    "    if shp_log[i] == 1:\n",
    "        shapefile = shapefile1\n",
    "    \n",
    "    elif shp_log[i] == 2:\n",
    "        shapefile = shapefile2\n",
    "    \n",
    "    # print(shapefile)\n",
    "    \n",
    "    precip_folder = '/global/scratch/users/arvalcarcel/CSMUB/DATA/PRECIP/RESAMPLED/'\n",
    "    date_input = date[i][-2:]\n",
    "    # print(date_input)\n",
    "\n",
    "\n",
    "    # ==== INPUT FILES ====\n",
    "    shapefile_path = shapefile\n",
    "    netcdf_path = precip_folder + 'IMERG-Final.CLIM.2001-2022.08.V07B.nc4'  # Update to your date/month\n",
    "\n",
    "    # ==== LOAD SHAPEFILE ====\n",
    "    shp = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "    geom = shp.geometry.union_all()\n",
    "    \n",
    "    # ==== LOAD NETCDF DATA ====\n",
    "    ds = nc.Dataset(netcdf_path)\n",
    "    precip = ds.variables['precipitation'][:]\n",
    "    lat = ds.variables['lat'][:]\n",
    "    lon = ds.variables['lon'][:]\n",
    "    \n",
    "    # ==== HANDLE TIME DIMENSION ====\n",
    "    if precip.ndim == 3:\n",
    "        precip = precip.mean(axis=0)\n",
    "    \n",
    "    # ==== BOUNDING BOX MASK ====\n",
    "   # ==== Check and sort longitudes if needed ====\n",
    "    if not np.all(np.diff(lon) > 0):\n",
    "        print(\"Sorting longitudes...\")\n",
    "        sort_idx = np.argsort(lon)\n",
    "        lon = lon[sort_idx]\n",
    "        precip = precip[:, sort_idx]  # shape: (lat, lon)\n",
    "\n",
    "    # ==== Apply masking ====\n",
    "    minlon, minlat, maxlon, maxlat = geom.bounds\n",
    "    lat_mask = (lat >= minlat) & (lat <= maxlat)\n",
    "    lon_mask = (lon >= minlon) & (lon <= maxlon)\n",
    "    \n",
    "    lat_idx = np.where(lat_mask)[0]\n",
    "    lon_idx = np.where(lon_mask)[0]\n",
    "    \n",
    "    if len(lat_idx) == 0 or len(lon_idx) == 0:\n",
    "        print(\"No valid lat/lon cells within shape bounds.\")\n",
    "        exit()\n",
    "    \n",
    "    # Validate indexing\n",
    "    if lat_idx.max() >= precip.shape[0] or lon_idx.max() >= precip.shape[1]:\n",
    "        print(\"Lat/lon indices exceed precipitation array shape.\")\n",
    "        print(\"Lat index max:\", lat_idx.max(), \"Lat shape:\", precip.shape[0])\n",
    "        print(\"Lon index max:\", lon_idx.max(), \"Lon shape:\", precip.shape[1])\n",
    "        exit()\n",
    "    \n",
    "    # Final extraction\n",
    "    lat_filtered = lat[lat_idx]\n",
    "    lon_filtered = lon[lon_idx]\n",
    "    precip_filtered = precip[np.ix_(lat_idx, lon_idx)]\n",
    "\n",
    "\n",
    "    \n",
    "    # ==== CREATE MESHGRID ====\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_filtered, lat_filtered)\n",
    "    \n",
    "    # ==== PLOTTING ====\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Use pcolormesh or contourf (contourf is smoother)\n",
    "    cf = ax.contourf(lon_grid, lat_grid, precip_filtered, cmap='viridis', levels=20)\n",
    "    shp.boundary.plot(ax=ax, color='red', linewidth=1)\n",
    "    \n",
    "    # Add labels\n",
    "    plt.colorbar(cf, ax=ax, label='Precipitation (mm)')\n",
    "    ax.set_title('Precipitation over Shapefile Area')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # # Compute avg precip for this date and shapefile\n",
    "    # avg = average_precip_single(shapefile, precip_folder, date_input, plot=True)\n",
    "    # # print(avg)\n",
    "    # # Assign result back to the matching rows\n",
    "    # precip[i] = avg*1e6\n",
    "    # # print(precip[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0125f65d-af05-44c8-802b-68838ce45aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df['P'] = precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962bdf49-ebf3-4a53-a8a2-7ada2b060da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0     Date       Q       SWE    SWE_scaled  GRDC_No  SHP  \\\n",
      "0               0  2018-08  24.526  2.087791  1.809042e+06  1159100    1   \n",
      "1               1  2018-09  31.372  1.835435  1.590379e+06  1159100    1   \n",
      "2               2  2018-10  19.572  1.976332  1.712464e+06  1159100    1   \n",
      "3               3  2018-11   7.349  1.633273  1.415208e+06  1159100    1   \n",
      "4               4  2018-12  13.824  1.782850  1.544815e+06  1159100    1   \n",
      "...           ...      ...     ...       ...           ...      ...  ...   \n",
      "23053          57  2023-05   3.046  3.400061  5.610100e+04  6594090    1   \n",
      "23054          58  2023-06   2.489  3.195970  5.273351e+04  6594090    1   \n",
      "23055          59  2023-07   2.021  3.656259  6.032828e+04  6594090    2   \n",
      "23056          60  2023-08   2.067  3.578097  5.903860e+04  6594090    1   \n",
      "23057          61  2023-09   2.483  3.630205  5.989839e+04  6594090    1   \n",
      "\n",
      "           Area  Latitude  Avg Slope  Max Slope     Aridity    Precip    P  \n",
      "0      866486.0 -28.75799   0.745665  22.007082   907.27856  3.059264  NaN  \n",
      "1      866486.0 -28.75799   0.745665  22.007082   907.27856  2.724767  0.0  \n",
      "2      866486.0 -28.75799   0.745665  22.007082   907.27856  8.292236  0.0  \n",
      "3      866486.0 -28.75799   0.745665  22.007082   907.27856  3.910201  0.0  \n",
      "4      866486.0 -28.75799   0.745665  22.007082   907.27856  9.718854  0.0  \n",
      "...         ...       ...        ...        ...         ...       ...  ...  \n",
      "23053   16500.0  31.84000   2.749054  25.081081  1116.96740  9.791268  0.0  \n",
      "23054   16500.0  31.84000   2.749054  25.081081  1116.96740  3.322466  0.0  \n",
      "23055   16500.0  31.84000   2.749054  25.081081  1116.96740  1.861580  0.0  \n",
      "23056   16500.0  31.84000   2.749054  25.081081  1116.96740  1.066341  0.0  \n",
      "23057   16500.0  31.84000   2.749054  25.081081  1116.96740  4.321275  0.0  \n",
      "\n",
      "[23058 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51473bca-873f-4759-b0e4-08a7d6291e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opened = []\n",
    "\n",
    "# csv_path = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/CSV/'\n",
    "# masterlist = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/ALL_STATIONS_REVISED_PRECIP.csv'\n",
    "\n",
    "# # Load the master list of stations\n",
    "# stations_df = pd.read_csv(masterlist)\n",
    "\n",
    "# # Extract station numbers, areas, and latitudes\n",
    "# station_num = stations_df['grdc_no']\n",
    "# station_shp = stations_df['shapefile_code']\n",
    "# station_area = stations_df['area']\n",
    "# station_lat = stations_df['lat']\n",
    "# station_avgslope = stations_df['avg_slope']\n",
    "# station_maxslope = stations_df['max_slope']\n",
    "# station_aridity = stations_df['avg_aridity']\n",
    "# station_precip = stations_df['P']\n",
    "\n",
    "# # Map station numbers to areas and latitudes\n",
    "# station_area_map = dict(zip(station_num, station_area))\n",
    "# station_lat_map = dict(zip(station_num, station_lat))\n",
    "# station_avgslope_map = dict(zip(station_num, station_avgslope))\n",
    "# station_maxslope_map = dict(zip(station_num, station_maxslope))\n",
    "# station_aridity_map = dict(zip(station_num, station_aridity))\n",
    "# # station_precip_map = dict(zip(station_num, station_precip))\n",
    "\n",
    "# # Generate the list of file paths\n",
    "# arrayFile = [os.path.join(csv_path, f\"{station_no}.csv\") for station_no in station_num]\n",
    "# # print(arrayFile)\n",
    "# # Initialize a list to store opened DataFrames\n",
    "# for file in arrayFile:\n",
    "#     station_no = os.path.basename(file).split('.')[0]\n",
    "#     # print(station_no)# Extract station number from the filename\n",
    "#     if os.path.exists(file):  # Check if file exists\n",
    "#         df = pd.read_csv(file, index_col=None, header=0)\n",
    "#         station_no_int = int(station_no)  # Convert station number to integer for lookup\n",
    "#         df['GRDC_No'] = station_no_int  # Add the station number as a new column\n",
    "#         df['SHP'] = station_shp\n",
    "#         df['Area'] = station_area_map.get(station_no_int, None)  # Add the Area column\n",
    "#         df['Latitude'] = station_lat_map.get(station_no_int, None)  # Add the latitude column\n",
    "#         df['Avg Slope'] = station_avgslope_map.get(station_no_int, None)\n",
    "#         df['Max Slope'] = station_maxslope_map.get(station_no_int, None)\n",
    "#         df['Aridity'] = station_aridity_map.get(station_no_int, None)\n",
    "#         df['Precip'] = station_precip\n",
    "#         opened.append(df)\n",
    "\n",
    "# # Combine all DataFrames into one\n",
    "# total_df = pd.concat(opened, axis=0, ignore_index=True)\n",
    "\n",
    "# # Print or save the resulting DataFrame\n",
    "# print(total_df)\n",
    "# total_df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
