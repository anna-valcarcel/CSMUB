{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22c0a9c4-8bd7-423f-9a98-5a1106efd184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import SimpleRNN , Input,Flatten, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from keras import initializers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24a71e2c-2f9c-4c14-a4eb-09a584f9a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     Date       Q       SWE   SWE_scaled  GRDC_No  SHP      Area  \\\n",
      "0           0  2018-08  24.526  2.087791  1809042.021  1159100    1  866486.0   \n",
      "1           1  2018-09  31.372  1.835435  1590378.590  1159100    1  866486.0   \n",
      "2           2  2018-10  19.572  1.976332  1712463.856  1159100    1  866486.0   \n",
      "3           3  2018-11   7.349  1.633273  1415208.035  1159100    1  866486.0   \n",
      "4           4  2018-12  13.824  1.782850  1544814.625  1159100    1  866486.0   \n",
      "\n",
      "   Latitude  Avg Slope  Max Slope    Aridity    Precip             P  \n",
      "0 -28.75799   0.745665  22.007082  907.27856  3.059264  2.298018e+05  \n",
      "1 -28.75799   0.745665  22.007082  907.27856  2.724767  2.989010e+05  \n",
      "2 -28.75799   0.745665  22.007082  907.27856  8.292236  8.098043e+05  \n",
      "3 -28.75799   0.745665  22.007082  907.27856  3.910201  1.301366e+06  \n",
      "4 -28.75799   0.745665  22.007082  907.27856  9.718854  1.729622e+06  \n"
     ]
    }
   ],
   "source": [
    "opened = []\n",
    "\n",
    "csv_path = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/CSV/'\n",
    "masterlist = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/ALL_STATIONS_ALL_MONTHS_PRECIP.csv'\n",
    "\n",
    "# Load the master list of stations\n",
    "total_df = pd.read_csv(masterlist)\n",
    "print(total_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2695783-7f50-4cf5-afd5-8e5e25677b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     Date       Q       SWE   SWE_scaled  GRDC_No  SHP      Area  \\\n",
      "0           0  2018-08  24.526  2.087791  1809042.021  1159100    1  866486.0   \n",
      "1           1  2018-09  31.372  1.835435  1590378.590  1159100    1  866486.0   \n",
      "2           2  2018-10  19.572  1.976332  1712463.856  1159100    1  866486.0   \n",
      "3           3  2018-11   7.349  1.633273  1415208.035  1159100    1  866486.0   \n",
      "4           4  2018-12  13.824  1.782850  1544814.625  1159100    1  866486.0   \n",
      "\n",
      "   Latitude  Avg Slope  ...        11        12        13        14        15  \\\n",
      "0 -28.75799   0.745665  ...  0.725055  0.678026  0.634266  0.625967  0.632506   \n",
      "1 -28.75799   0.745665  ...  0.725055  0.678026  0.634266  0.625967  0.632506   \n",
      "2 -28.75799   0.745665  ...  0.725055  0.678026  0.634266  0.625967  0.632506   \n",
      "3 -28.75799   0.745665  ...  0.725055  0.678026  0.634266  0.625967  0.632506   \n",
      "4 -28.75799   0.745665  ...  0.725055  0.678026  0.634266  0.625967  0.632506   \n",
      "\n",
      "         16       17        18   19  20  \n",
      "0  0.746809  0.80591  0.086011  0.0   0  \n",
      "1  0.746809  0.80591  0.086011  0.0   0  \n",
      "2  0.746809  0.80591  0.086011  0.0   0  \n",
      "3  0.746809  0.80591  0.086011  0.0   0  \n",
      "4  0.746809  0.80591  0.086011  0.0   0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "landcover = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/CSV/ALL_STATIONS_LANDCOVER.csv'\n",
    "landcover_df = pd.read_csv(landcover)\n",
    "\n",
    "# Ensure number and GRDC_No are of the same type\n",
    "total_df['GRDC_No'] = total_df['GRDC_No'].astype(int)\n",
    "landcover_df['number'] = landcover_df['number'].astype(int)\n",
    "\n",
    "# Initialize empty lists for new columns\n",
    "new_columns = {col: [] for col in landcover_df.columns if col != 'number'}\n",
    "\n",
    "# Loop through total_df and match with landcover_df\n",
    "for grdc_no in total_df['GRDC_No']:\n",
    "    match = landcover_df[landcover_df['number'] == grdc_no]\n",
    "    \n",
    "    if not match.empty:\n",
    "        for col in new_columns:\n",
    "            new_columns[col].append(match[col].values[0])  # Append matched value\n",
    "    else:\n",
    "        for col in new_columns:\n",
    "            new_columns[col].append(None)  # Append NaN if no match found\n",
    "\n",
    "# Convert lists to a DataFrame and concatenate with total_df\n",
    "new_data = pd.DataFrame(new_columns)\n",
    "total_df = pd.concat([total_df, new_data], axis=1)\n",
    "\n",
    "print(total_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bbe9c49-a524-4151-9260-9daee75f760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     Date       Q       SWE   SWE_scaled  GRDC_No  SHP      Area  \\\n",
      "0           0  2018-08  24.526  2.087791  1809042.021  1159100    1  866486.0   \n",
      "1           1  2018-09  31.372  1.835435  1590378.590  1159100    1  866486.0   \n",
      "2           2  2018-10  19.572  1.976332  1712463.856  1159100    1  866486.0   \n",
      "3           3  2018-11   7.349  1.633273  1415208.035  1159100    1  866486.0   \n",
      "4           4  2018-12  13.824  1.782850  1544814.625  1159100    1  866486.0   \n",
      "\n",
      "   Latitude  Avg Slope  ...         7         8         9        10       11  \\\n",
      "0 -28.75799   0.745665  ...  1.132788  1.497797  5.198238  0.453115  0.98175   \n",
      "1 -28.75799   0.745665  ...  1.132788  1.497797  5.198238  0.453115  0.98175   \n",
      "2 -28.75799   0.745665  ...  1.132788  1.497797  5.198238  0.453115  0.98175   \n",
      "3 -28.75799   0.745665  ...  1.132788  1.497797  5.198238  0.453115  0.98175   \n",
      "4 -28.75799   0.745665  ...  1.132788  1.497797  5.198238  0.453115  0.98175   \n",
      "\n",
      "        12   13   14   15   16  \n",
      "0  2.17747  0.0  0.0  0.0  0.0  \n",
      "1  2.17747  0.0  0.0  0.0  0.0  \n",
      "2  2.17747  0.0  0.0  0.0  0.0  \n",
      "3  2.17747  0.0  0.0  0.0  0.0  \n",
      "4  2.17747  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "soiltype = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/CSV/ALL_STATIONS_SOILTYPE.csv'\n",
    "soiltype_df = pd.read_csv(soiltype)\n",
    "# print(soiltype_df.head())\n",
    "# Ensure number and GRDC_No are of the same type\n",
    "total_df['GRDC_No'] = total_df['GRDC_No'].astype(int)\n",
    "soiltype_df['number'] = soiltype_df['number'].astype(int)\n",
    "\n",
    "# Initialize empty lists for new columns\n",
    "new_columns = {col: [] for col in soiltype_df.columns if col != 'number'}\n",
    "\n",
    "# Loop through total_df and match with landcover_df\n",
    "for grdc_no in total_df['GRDC_No']:\n",
    "    match = soiltype_df[soiltype_df['number'] == grdc_no]\n",
    "    \n",
    "    if not match.empty:\n",
    "        for col in new_columns:\n",
    "            new_columns[col].append(match[col].values[0])  # Append matched value\n",
    "    else:\n",
    "        for col in new_columns:\n",
    "            new_columns[col].append(None)  # Append NaN if no match found\n",
    "\n",
    "# Convert lists to a DataFrame and concatenate with total_df\n",
    "new_data = pd.DataFrame(new_columns)\n",
    "total_df = pd.concat([total_df, new_data], axis=1)\n",
    "\n",
    "print(total_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f26f4652-d0c6-4cd5-9d25-3b1aac267856",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = total_df['Q']\n",
    "swe = total_df['SWE']\n",
    "scaled = total_df['SWE_scaled']\n",
    "area = total_df['Area']\n",
    "station = total_df['GRDC_No']\n",
    "lat = total_df['Latitude']\n",
    "avg_slope = total_df['Avg Slope']\n",
    "max_slope = total_df['Max Slope']\n",
    "precip = total_df['P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f05a1e4-d159-4c85-a20b-d551ac921a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1          2          3         4         5         6         7  \\\n",
      "0      6.136561  60.524866  17.803458  3.554480  1.860924  1.402201  1.166174   \n",
      "1      6.136561  60.524866  17.803458  3.554480  1.860924  1.402201  1.166174   \n",
      "2      6.136561  60.524866  17.803458  3.554480  1.860924  1.402201  1.166174   \n",
      "3      6.136561  60.524866  17.803458  3.554480  1.860924  1.402201  1.166174   \n",
      "4      6.136561  60.524866  17.803458  3.554480  1.860924  1.402201  1.166174   \n",
      "...         ...        ...        ...       ...       ...       ...       ...   \n",
      "23053  5.348157  14.675249  16.582797  9.654769  5.874781  4.628438  4.253950   \n",
      "23054  5.348157  14.675249  16.582797  9.654769  5.874781  4.628438  4.253950   \n",
      "23055  5.348157  14.675249  16.582797  9.654769  5.874781  4.628438  4.253950   \n",
      "23056  5.348157  14.675249  16.582797  9.654769  5.874781  4.628438  4.253950   \n",
      "23057  5.348157  14.675249  16.582797  9.654769  5.874781  4.628438  4.253950   \n",
      "\n",
      "              8         9        10        11        12        13        14  \\\n",
      "0      0.984093  0.847784  0.784910  0.725055  0.678026  0.634266  0.625967   \n",
      "1      0.984093  0.847784  0.784910  0.725055  0.678026  0.634266  0.625967   \n",
      "2      0.984093  0.847784  0.784910  0.725055  0.678026  0.634266  0.625967   \n",
      "3      0.984093  0.847784  0.784910  0.725055  0.678026  0.634266  0.625967   \n",
      "4      0.984093  0.847784  0.784910  0.725055  0.678026  0.634266  0.625967   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "23053  3.815097  3.557636  3.346987  3.335284  3.060269  2.873025  3.200702   \n",
      "23054  3.815097  3.557636  3.346987  3.335284  3.060269  2.873025  3.200702   \n",
      "23055  3.815097  3.557636  3.346987  3.335284  3.060269  2.873025  3.200702   \n",
      "23056  3.815097  3.557636  3.346987  3.335284  3.060269  2.873025  3.200702   \n",
      "23057  3.815097  3.557636  3.346987  3.335284  3.060269  2.873025  3.200702   \n",
      "\n",
      "             15        16        17        18   19  20  \n",
      "0      0.632506  0.746809  0.805910  0.086011  0.0   0  \n",
      "1      0.632506  0.746809  0.805910  0.086011  0.0   0  \n",
      "2      0.632506  0.746809  0.805910  0.086011  0.0   0  \n",
      "3      0.632506  0.746809  0.805910  0.086011  0.0   0  \n",
      "4      0.632506  0.746809  0.805910  0.086011  0.0   0  \n",
      "...         ...       ...       ...       ...  ...  ..  \n",
      "23053  3.581042  5.652428  4.897601  1.661791  0.0   0  \n",
      "23054  3.581042  5.652428  4.897601  1.661791  0.0   0  \n",
      "23055  3.581042  5.652428  4.897601  1.661791  0.0   0  \n",
      "23056  3.581042  5.652428  4.897601  1.661791  0.0   0  \n",
      "23057  3.581042  5.652428  4.897601  1.661791  0.0   0  \n",
      "\n",
      "[23058 rows x 20 columns]\n",
      "         1         2          3        4         5          6          7  \\\n",
      "0      0.0  8.105727  47.702958  2.54248  5.966016  24.241661   1.132788   \n",
      "1      0.0  8.105727  47.702958  2.54248  5.966016  24.241661   1.132788   \n",
      "2      0.0  8.105727  47.702958  2.54248  5.966016  24.241661   1.132788   \n",
      "3      0.0  8.105727  47.702958  2.54248  5.966016  24.241661   1.132788   \n",
      "4      0.0  8.105727  47.702958  2.54248  5.966016  24.241661   1.132788   \n",
      "...    ...       ...        ...      ...       ...        ...        ...   \n",
      "23053  0.0  0.000000   0.000000  0.00000  0.000000  19.277108  12.650602   \n",
      "23054  0.0  0.000000   0.000000  0.00000  0.000000  19.277108  12.650602   \n",
      "23055  0.0  0.000000   0.000000  0.00000  0.000000  19.277108  12.650602   \n",
      "23056  0.0  0.000000   0.000000  0.00000  0.000000  19.277108  12.650602   \n",
      "23057  0.0  0.000000   0.000000  0.00000  0.000000  19.277108  12.650602   \n",
      "\n",
      "               8          9        10         11        12   13   14   15   16  \n",
      "0       1.497797   5.198238  0.453115   0.981750  2.177470  0.0  0.0  0.0  0.0  \n",
      "1       1.497797   5.198238  0.453115   0.981750  2.177470  0.0  0.0  0.0  0.0  \n",
      "2       1.497797   5.198238  0.453115   0.981750  2.177470  0.0  0.0  0.0  0.0  \n",
      "3       1.497797   5.198238  0.453115   0.981750  2.177470  0.0  0.0  0.0  0.0  \n",
      "4       1.497797   5.198238  0.453115   0.981750  2.177470  0.0  0.0  0.0  0.0  \n",
      "...          ...        ...       ...        ...       ...  ...  ...  ...  ...  \n",
      "23053  15.060241  13.253012  8.433735  23.493976  7.831325  0.0  0.0  0.0  0.0  \n",
      "23054  15.060241  13.253012  8.433735  23.493976  7.831325  0.0  0.0  0.0  0.0  \n",
      "23055  15.060241  13.253012  8.433735  23.493976  7.831325  0.0  0.0  0.0  0.0  \n",
      "23056  15.060241  13.253012  8.433735  23.493976  7.831325  0.0  0.0  0.0  0.0  \n",
      "23057  15.060241  13.253012  8.433735  23.493976  7.831325  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[23058 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "lc_types = total_df.iloc[:, 14:-16]\n",
    "soil_types = total_df.iloc[:, -16:]\n",
    "\n",
    "# lc_types = lc_types/100\n",
    "# soil_types = soil_types/100\n",
    "\n",
    "print(lc_types)\n",
    "print(soil_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9d4f7c4-1579-41ee-9e5d-f7d62ddb6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.80904202e+06  8.66486000e+05 -2.87579900e+01  7.45665431e-01\n",
      "  2.20070820e+01  2.29801800e+05  2.00000000e+00  3.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "\n",
    "lc_in = lc_types.idxmax(axis=1)\n",
    "soil_in = soil_types.idxmax(axis=1)\n",
    "# print(lc_class)\n",
    "\n",
    "# lat_in = (lat*np.pi)/180\n",
    "# Convert q and swe to NumPy arrays\n",
    "scaled_in = scaled.to_numpy()  # Assume scaled is a pandas Series\n",
    "area_in = area.to_numpy()      # Assume area is a pandas Series\n",
    "lat_in = lat.to_numpy()\n",
    "avg_slope_in = avg_slope.to_numpy()\n",
    "# avg_slope_in = (avg_slope_in*np.pi)/180\n",
    "max_slope_in = max_slope.to_numpy()\n",
    "# max_slope_in = (max_slope_in*np.pi)/180\n",
    "# avg_p_in = precip.to_numpy()\n",
    "y = q.to_numpy()            # Target variable\n",
    "\n",
    "lc_in = [int(item) for item in lc_in]\n",
    "soil_in = [int(item) for item in soil_in]\n",
    "\n",
    "# Convert q and swe to NumPy arrays\n",
    "# scaled_in = scaled_in/max(scaled_in)  # Assume scaled is a pandas Series\n",
    "# area_in = area_in/max(area_in)      # Assume area is a pandas Series\n",
    "# lat_in = lat_in/180\n",
    "# avg_slope_in = avg_slope_in/180\n",
    "# max_slope_in = max_slope_in/180\n",
    "# avg_aridity_in = avg_aridity_in/max(avg_aridity_in)\n",
    "# y = y/max(y)            # Target variable\n",
    "# lc_in = lc_types/max(lc_types)\n",
    "# soil_in = soil_types/max(soil_types)\n",
    "\n",
    "# Step 1: Replace zeros with a small value\n",
    "scaled_in[scaled_in == 0] = 1e-9\n",
    "area_in[area_in == 0] = 1e-9\n",
    "lat_in[lat_in == 0] = 1e-9\n",
    "avg_slope_in[avg_slope_in == 0] = 1e-9\n",
    "max_slope_in[max_slope_in == 0] = 1e-9\n",
    "avg_p_in[avg_p_in == 0] = 1e-9\n",
    "y[y == 0] = 1e-9\n",
    "\n",
    "# Step 2: Combine features into a 2D array\n",
    "X = np.column_stack((scaled_in, area_in, lat_in, avg_slope_in, max_slope_in, avg_p_in, lc_in, soil_in))  # Shape will be (num_samples, 2)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "decb70a1-ed4d-4c93-bdcb-06cc21e46657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. Standardize the data (each column)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. Apply PCA\n",
    "pca = PCA(n_components=2)  # for example, reduce to 2 components\n",
    "X_pca = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfad9bb9-8037-44d3-9dfe-935e17bc26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.28460557 0.22839447 0.15484371]\n",
      "Top features for PC1:\n",
      "Precip          0.625889\n",
      "Avg Slope       0.497800\n",
      "Land Cover      0.419586\n",
      "Max Slope       0.287268\n",
      "Soil Texture    0.211896\n",
      "Latitude        0.165124\n",
      "Area            0.160052\n",
      "SWE             0.064032\n",
      "Name: PC3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_scaled)\n",
    "pca_X = pca.transform(X_scaled)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "pca_df = pd.DataFrame(data=pca_X, columns=['pc1','pc2','pc3'])\n",
    "\n",
    "# Display the explained variance ratio\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "\n",
    "# To see the importance of each feature for the principal components\n",
    "# The components_ attribute holds the loadings (how much each feature contributes to each principal component)\n",
    "loadings = pd.DataFrame(pca.components_, columns=['SWE','Area','Latitude','Avg Slope','Max Slope','Precip','Land Cover','Soil Texture'], index=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
    "# print(loadings)\n",
    "\n",
    "# Optionally, you can sort the loadings to identify the most important features\n",
    "# Example: Sort by PC1 loadings\n",
    "print(\"Top features for PC1:\")\n",
    "print(loadings.loc['PC3'].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2db4ee8-8156-4848-8544-c59675fcff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Top Feature  Explained Variance Ratio\n",
      "PC1   Max Slope                  0.284606\n",
      "PC2         SWE                  0.228394\n",
      "PC3      Precip                  0.154844\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X is your original DataFrame\n",
    "feature_names = ['SWE','Area','Latitude','Avg Slope','Max Slope','Precip','Land Cover','Soil Texture']\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_X = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Loadings matrix (PCs × features)\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_, \n",
    "    columns=feature_names, \n",
    "    index=[f'PC{i+1}' for i in range(pca.n_components_)]\n",
    ")\n",
    "\n",
    "# Get top feature for each PC\n",
    "top_features = loadings.abs().idxmax(axis=1)\n",
    "\n",
    "# Combine with explained variance ratio\n",
    "explained_variance_summary = pd.DataFrame({\n",
    "    'Top Feature': top_features,\n",
    "    'Explained Variance Ratio': pca.explained_variance_ratio_\n",
    "})\n",
    "\n",
    "print(explained_variance_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61070ad2-b186-4331-b692-fa923f93dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01020457  0.00473088  0.01088511 ... -0.00106247  0.00578572\n",
      "   0.03134196]\n",
      " [-0.00999381  0.00448557  0.01073718 ... -0.00127046  0.00610359\n",
      "   0.03319683]\n",
      " [-0.00997852  0.00494281  0.00996465 ... -0.00241469  0.00592923\n",
      "   0.03234889]\n",
      " ...\n",
      " [-0.00356639 -0.0050305  -0.0026025  ...  0.0066166   0.0074925\n",
      "  -0.00076681]\n",
      " [-0.00356676 -0.00503583 -0.00259299 ...  0.00663068  0.00749434\n",
      "  -0.00075815]\n",
      " [-0.00356429 -0.00502693 -0.00261361 ...  0.00660025  0.00749316\n",
      "  -0.00076079]]\n"
     ]
    }
   ],
   "source": [
    "U, D, VT = np.linalg.svd(X_scaled, full_matrices=False)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c5a62da-76a0-40f2-8dde-20df4b07ee47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m residuals \u001b[38;5;241m=\u001b[39m y_test \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(y_test, residuals)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39maxhline(\u001b[38;5;241m0\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "residuals = y_test - model.predict(X_test)\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291530c-2b52-42dd-bb1f-7fc94e4f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y_test and y_pred as a time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(len(y_test)), y_test*max(y), label=\"Actual Values (y_test)\", color=\"blue\", alpha=0.7)\n",
    "plt.plot(np.arange(len(y_pred)), y_pred*max(y), label=\"Predicted Values (y_pred)\", color=\"red\", alpha=0.7)\n",
    "plt.title(\"Actual vs Predicted Values of Test Dataset\")\n",
    "plt.xlabel(\"Test Dataset\")\n",
    "plt.ylabel(\"Streamflow [m${^3}$/s]\")\n",
    "plt.xlim(0,len(y_test))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3555a-6f60-440e-852d-d53b7a29fb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot y_test and y_pred as a time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot((np.arange(len(y_test)))[0:500], (y_test*max(y))[0:500], label=\"Actual Values (y_test)\", color=\"blue\", alpha=0.7)\n",
    "plt.plot((np.arange(len(y_pred)))[0:500], (y_pred*max(y))[0:500], label=\"Predicted Values (y_pred)\", color=\"red\", alpha=0.7)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Actual vs Predicted Values of Test Dataset (element 0 to 500)\")\n",
    "plt.xlabel(\"Test Dataset\")\n",
    "plt.ylabel(\"Streamflow [m${^3}$/s]\")\n",
    "# plt.xlim(0,len(y_test))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31313ea-9c5b-469f-93c1-c104b5df69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(scaled,q)\n",
    "plt.title('Raw Data - All Basins')\n",
    "plt.xlabel('Surface Water Extent Area [km${^2}$]')\n",
    "plt.ylabel('Streamflow [m${^3}$/s]')\n",
    "# plt.savefig('global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rawdata.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006963d-0708-4102-833b-7ed7596a5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(area,q,color='g')\n",
    "plt.title('Raw Data - All Basins')\n",
    "plt.xlabel('Total Basin Area [km${^2}$]')\n",
    "plt.ylabel('Streamflow [m${^3}$/s]')\n",
    "# plt.savefig('global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rawdata.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59885bec-2ec6-4b93-82de-a2585e2ce843",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lat,q,color='r')\n",
    "plt.title('Raw Data - All Basins')\n",
    "plt.xlabel('Latitude [deg]')\n",
    "plt.ylabel('Streamflow [m${^3}$/s]')\n",
    "# plt.savefig('global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rawdata.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017459b5-e7da-49d5-adc9-832a261d3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(max_slope,q,color='purple')\n",
    "plt.title('Raw Data - All Basins')\n",
    "plt.xlabel('Max Slope [deg]')\n",
    "plt.ylabel('Streamflow [m${^3}$/s]')\n",
    "# plt.savefig('global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rawdata.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589bbdf-bbe6-414a-81fa-12e47bf8dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_class = lc_types.idxmax(axis=1)\n",
    "plt.scatter(lc_class,q,color='orange')\n",
    "plt.title('Raw Data - All Basins')\n",
    "plt.xlabel('Land Cover Type')\n",
    "plt.ylabel('Streamflow [m${^3}$/s]')\n",
    "# plt.savefig('global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rawdata.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade19ef-75d4-4940-b49f-c0c775061bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soil_class = soil_types.idxmax(axis=1)\n",
    "\n",
    "plt.scatter(soil_class,q,color='darkorange')\n",
    "plt.title('Raw Data - All Basins')\n",
    "plt.xlabel('Soil Texture')\n",
    "plt.ylabel('Streamflow [m${^3}$/s]')\n",
    "# plt.savefig('global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rawdata.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5644d7-eb60-4f52-bf39-667ae642a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = total_df.groupby('Area')['Q'].mean()\n",
    "\n",
    "# Extract unique areas and their corresponding average Q values\n",
    "area_unique = grouped.index\n",
    "q_avg = grouped.values\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(area_unique, q_avg, color='g')\n",
    "plt.xlabel('Total Basin Area')\n",
    "plt.ylabel('Average Streamflow')\n",
    "plt.title('Average Streamflow vs Total Basin Area')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b731448-0d5e-4deb-b732-0e7eef979259",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = total_df.groupby('Latitude')['Q'].mean()\n",
    "\n",
    "# Extract unique areas and their corresponding average Q values\n",
    "lat_unique = grouped.index\n",
    "q_avg = grouped.values\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(lat_unique, q_avg,color='red')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Average Streamflow')\n",
    "plt.title('Average Streamflow vs Basin Latitude')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c2122-8f97-4ca9-a2ca-61a3b6588fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/global/scratch/users/arvalcarcel/CSMUB/RESULTS/CNN/rnn_plot.png'\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Plot and save the model\n",
    "plot_model(model, to_file=filename, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
